name: Quality Gate

# Run on PRs that touch search/retrieval/assumption code
on:
  pull_request:
    branches: [main]
    paths:
      - 'packages/storage/src/**'
      - 'packages/pdf-tools/src/**'
      - 'packages/mcp-server/src/**'
      - 'fixtures/eval/**'
      - 'scripts/eval_retrieval.py'
      - 'scripts/eval_assumptions.py'

jobs:
  eval:
    name: Retrieval Evaluation
    runs-on: ubuntu-latest
    timeout-minutes: 15

    services:
      postgres:
        image: ankane/pgvector:latest
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: research_kb
        ports:
          - 5432:5432
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e packages/cli
          pip install -e packages/storage
          pip install -e packages/pdf-tools
          pip install -e packages/contracts
          pip install -e packages/common
          pip install pyyaml numpy scikit-learn

      # Restore cached database snapshot for evaluation
      - name: Restore database cache
        uses: actions/cache@v4
        with:
          path: ~/.cache/research-kb
          key: research-kb-eval-db-${{ hashFiles('fixtures/eval/**') }}
          restore-keys: |
            research-kb-eval-db-

      - name: Initialize database
        env:
          POSTGRES_HOST: localhost
          POSTGRES_PORT: 5432
          POSTGRES_DB: research_kb
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
        run: |
          # Apply migrations
          for migration in packages/storage/migrations/*.sql; do
            psql -h localhost -U postgres -d research_kb -f "$migration" || true
          done

      - name: Run retrieval evaluation
        id: eval
        env:
          POSTGRES_HOST: localhost
          POSTGRES_PORT: 5432
          POSTGRES_DB: research_kb
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
        run: |
          python scripts/eval_retrieval.py --output metrics.json || true
          cat metrics.json

      - name: Check quality thresholds
        run: |
          echo "Checking quality thresholds..."

          # Extract metrics
          HIT_RATE=$(jq -r '.hit_rate_at_k' metrics.json)
          MRR=$(jq -r '.mrr' metrics.json)
          NDCG=$(jq -r '.ndcg_5' metrics.json)
          CONCEPT_RECALL=$(jq -r '.concept_recall // 1.0' metrics.json)

          echo "Hit Rate@K: $HIT_RATE (threshold: 0.80)"
          echo "MRR: $MRR (threshold: 0.50 - warning only)"
          echo "NDCG@5: $NDCG (threshold: 0.70 - warning only)"
          echo "Concept Recall: $CONCEPT_RECALL (threshold: 0.70)"

          # Required thresholds (fail build if not met)
          FAIL=0

          if (( $(echo "$HIT_RATE < 0.80" | bc -l) )); then
            echo "::error::Hit Rate@K below threshold: $HIT_RATE < 0.80"
            FAIL=1
          fi

          if (( $(echo "$CONCEPT_RECALL < 0.70" | bc -l) )); then
            echo "::warning::Concept Recall below threshold: $CONCEPT_RECALL < 0.70"
            # Note: Warning only for concept recall until we have more test cases
          fi

          # Warning thresholds (don't fail build)
          if (( $(echo "$MRR < 0.50" | bc -l) )); then
            echo "::warning::MRR below preferred threshold: $MRR < 0.50"
          fi

          if (( $(echo "$NDCG < 0.70" | bc -l) )); then
            echo "::warning::NDCG@5 below preferred threshold: $NDCG < 0.70"
          fi

          exit $FAIL

      - name: Upload metrics artifact
        uses: actions/upload-artifact@v4
        with:
          name: retrieval-metrics
          path: metrics.json
          retention-days: 30

      - name: Post comment with metrics
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const metrics = JSON.parse(fs.readFileSync('metrics.json', 'utf8'));

            const hitRate = (metrics.hit_rate_at_k * 100).toFixed(1);
            const mrr = metrics.mrr.toFixed(3);
            const ndcg = metrics.ndcg_5.toFixed(3);
            const conceptRecall = metrics.concept_recall
              ? (metrics.concept_recall * 100).toFixed(1) + '%'
              : 'N/A';

            const body = `## Retrieval Quality Metrics

            | Metric | Value | Threshold | Status |
            |--------|-------|-----------|--------|
            | Hit Rate@K | ${hitRate}% | ≥80% | ${metrics.hit_rate_at_k >= 0.80 ? '✅' : '❌'} |
            | MRR | ${mrr} | ≥0.50 | ${metrics.mrr >= 0.50 ? '✅' : '⚠️'} |
            | NDCG@5 | ${ndcg} | ≥0.70 | ${metrics.ndcg_5 >= 0.70 ? '✅' : '⚠️'} |
            | Concept Recall | ${conceptRecall} | ≥70% | ${metrics.concept_recall >= 0.70 ? '✅' : '⚠️'} |

            <details>
            <summary>Raw metrics</summary>

            \`\`\`json
            ${JSON.stringify(metrics, null, 2)}
            \`\`\`
            </details>
            `;

            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: body
            });

  assumption-eval:
    name: Assumption Auditing Evaluation
    runs-on: ubuntu-latest
    timeout-minutes: 10

    services:
      postgres:
        image: ankane/pgvector:latest
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: research_kb
        ports:
          - 5432:5432
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e packages/storage
          pip install -e packages/contracts
          pip install -e packages/common

      - name: Restore database cache
        uses: actions/cache@v4
        with:
          path: ~/.cache/research-kb
          key: research-kb-eval-db-${{ hashFiles('fixtures/eval/**') }}
          restore-keys: |
            research-kb-eval-db-

      - name: Initialize database
        env:
          POSTGRES_HOST: localhost
          POSTGRES_PORT: 5432
          POSTGRES_DB: research_kb
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
        run: |
          for migration in packages/storage/migrations/*.sql; do
            psql -h localhost -U postgres -d research_kb -f "$migration" || true
          done

      - name: Run assumption evaluation (graph-only)
        id: assumption_eval
        env:
          POSTGRES_HOST: localhost
          POSTGRES_PORT: 5432
          POSTGRES_DB: research_kb
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
        run: |
          # Run without Ollama fallback (CI doesn't have Ollama)
          python scripts/eval_assumptions.py --output assumption_metrics.json || true
          cat assumption_metrics.json

      - name: Check assumption thresholds
        run: |
          echo "Checking assumption auditing thresholds..."

          RECALL=$(jq -r '.avg_recall' assumption_metrics.json)
          PRECISION=$(jq -r '.avg_precision' assumption_metrics.json)
          F1=$(jq -r '.avg_f1' assumption_metrics.json)
          PASSED=$(jq -r '.passed' assumption_metrics.json)

          echo "Average Recall: $RECALL (threshold: 0.60)"
          echo "Average Precision: $PRECISION (threshold: 0.10)"
          echo "Average F1: $F1"
          echo "Passed: $PASSED"

          # Note: Low precision is expected (system returns ALL assumptions, not just core ones)
          if [ "$PASSED" != "true" ]; then
            echo "::warning::Assumption evaluation did not meet thresholds"
            # Warning only - assumption auditing is still maturing
          fi

      - name: Upload assumption metrics
        uses: actions/upload-artifact@v4
        with:
          name: assumption-metrics
          path: assumption_metrics.json
          retention-days: 30

      - name: Post assumption metrics comment
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const metrics = JSON.parse(fs.readFileSync('assumption_metrics.json', 'utf8'));

            const recall = (metrics.avg_recall * 100).toFixed(1);
            const precision = (metrics.avg_precision * 100).toFixed(1);
            const f1 = (metrics.avg_f1 * 100).toFixed(1);
            const methodsWithResults = metrics.methods_with_results;
            const totalMethods = metrics.total_methods;

            const body = `## Assumption Auditing Metrics

            | Metric | Value | Threshold | Status |
            |--------|-------|-----------|--------|
            | Recall | ${recall}% | ≥60% | ${metrics.avg_recall >= 0.60 ? '✅' : '⚠️'} |
            | Precision | ${precision}% | ≥10% | ${metrics.avg_precision >= 0.10 ? '✅' : '⚠️'} |
            | F1 Score | ${f1}% | - | - |
            | Methods Found | ${methodsWithResults}/${totalMethods} | - | - |

            *Note: Low precision is expected - system returns all assumptions, not just core ones.*

            <details>
            <summary>Per-method breakdown</summary>

            | Method | Recall | Precision | Source |
            |--------|--------|-----------|--------|
            ${metrics.methods.map(m =>
              `| ${m.name} | ${(m.recall * 100).toFixed(0)}% | ${(m.precision * 100).toFixed(0)}% | ${m.source} |`
            ).join('\n')}
            </details>
            `;

            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: body
            });
